{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.__version__ # get the version of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_raw=pd.read_csv('/Users/francois-guillaume.rideau/Documents/Kaggle/Kaggle-SF/train.csv')\n",
    "df_test_raw=pd.read_csv('/Users/francois-guillaume.rideau/Documents/Kaggle/Kaggle-SF/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_raw.shape)\n",
    "print(df_test_raw.shape)\n",
    "Nobs_train_raw = df_raw.shape[0]\n",
    "Nobs_train_raw\n",
    "df_raw['Id']=range(Nobs_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minidf=df_raw.loc[0:5,:]\n",
    "minidf\n",
    "minidf_test=df_test_raw.loc[0:5,:]\n",
    "minidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_raw.describe() # shows one value for Y which is totally stupid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_raw[df_raw['Y']>38] # note that X is -120.5 for all those obs. We still have PdDistrict and Address...67 such OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_raw.isnull().values.any() # no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_raw.describe() # shows one value for Y which is totally stupid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_raw[df_test_raw['Y']>38] # note that X is -120.5 for all those obs. We still have PdDistrict and Address...76 such OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_raw.isnull().values.any() # no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converting columns to the proper format (training set)\n",
    "\n",
    "df_raw['Dates']=pd.to_datetime(df_raw['Dates'])\n",
    "\n",
    "def is_categorical_a(array_like):\n",
    "    return array_like.dtype.name == 'category'\n",
    "\n",
    "for col in ['Category', 'DayOfWeek', 'PdDistrict', 'Resolution']:\n",
    "    df_raw[col] = df_raw[col].astype('category')\n",
    "    \n",
    "df_raw.dtypes\n",
    "\n",
    "# converting columns to the proper format (test set)\n",
    "\n",
    "df_test_raw['Dates']=pd.to_datetime(df_test_raw['Dates'])\n",
    "\n",
    "for col in ['DayOfWeek', 'PdDistrict']:\n",
    "    df_test_raw[col] = df_test_raw[col].astype('category')\n",
    "    \n",
    "df_test_raw.dtypes\n",
    "df_t = df_test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a clean dataframe for the training test\n",
    "\n",
    "df=df_raw[df_raw['Y']<=38]\n",
    "\n",
    "# explore the dataframe\n",
    "df_raw['PdDistrict'].describe()\n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[:,'Hour']=df['Dates'].dt.hour\n",
    "df.loc[:,'Month']=df['Dates'].dt.month\n",
    "type(df.loc)\n",
    "# df['Hour']\n",
    "\n",
    "df_t.loc[:,'Hour']=df_t['Dates'].dt.hour\n",
    "df_t.loc[:,'Month']=df_t['Dates'].dt.month\n",
    "type(df_t.loc)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example how to make dummy variables\n",
    "s= pd.Series([\"Wednesday\",\"Tuesday\",\"Friday\",\"Thursday\",\"Saturday\",\"Sunday\",\"Monday\"], dtype=\"category\")\n",
    "s = s.cat.reorder_categories([\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"], ordered=True)\n",
    "pd.get_dummies(s, drop_first=True)\n",
    "\n",
    "df.loc[:,'DayOfWeek'] = df['DayOfWeek'].cat.reorder_categories([\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"], ordered=True)\n",
    "x=pd.get_dummies(df['DayOfWeek'], drop_first=True)\n",
    "y=pd.get_dummies(df['PdDistrict'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['Hour'].describe() # 0 to 23\n",
    "\n",
    "def hourslice2 (hour):\n",
    "    if   (hour==0)  or (hour==23) : return (\"23H - 0H\")\n",
    "    elif (hour==1)  or (hour==2)  : return (\" 1H - 2H\")\n",
    "    elif (hour==3)  or (hour==4)  : return (\" 3H - 4H\")\n",
    "    elif (hour==5)  or (hour==6)  : return (\" 5H - 6H\")\n",
    "    elif (hour==7)  or (hour==8)  : return (\" 7H - 8H\")\n",
    "    elif (hour==9)  or (hour==10) : return (\" 9H - 10H\")\n",
    "    elif (hour==11) or (hour==12) : return (\"11H - 12H\")\n",
    "    elif (hour==13) or (hour==14) : return (\"13H - 14H\")\n",
    "    elif (hour==15) or (hour==16) : return (\"15H - 16H\")\n",
    "    elif (hour==17) or (hour==18) : return (\"17H - 18H\")\n",
    "    elif (hour==19) or (hour==20) : return (\"19H - 20H\")\n",
    "    else                          : return (\"21H - 22H\")\n",
    "    \n",
    "df.loc[:,'hourslice2']=df.loc[:,'Hour'].apply(hourslice2)   \n",
    "z = pd.get_dummies(df['hourslice2'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def season(month):\n",
    "    if   (month==1) or (month==2) or (month==12) : return(\"winter\")\n",
    "    elif (month==3) or (month==4) or (month==5)  : return(\"spring\")\n",
    "    elif (month==6) or (month==7) or (month==8)  : return(\"summer\")\n",
    "    else                                         : return(\"autumn\")\n",
    "df.loc[:,'season']=df.loc[:,'Month'].apply(season)   \n",
    "t = pd.get_dummies(df['season'], drop_first=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, x,y,z,t], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myfun(y): return(y.value // 10**9)\n",
    "    \n",
    "df.loc[:,'Date_sec']=df['Dates'].apply(myfun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_t.loc[:,'DayOfWeek'] = df_t['DayOfWeek'].cat.reorder_categories([\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"], ordered=True)\n",
    "x=pd.get_dummies(df_t['DayOfWeek'], drop_first=True)\n",
    "y=pd.get_dummies(df_t['PdDistrict'], drop_first=True)\n",
    "df_t.loc[:,'hourslice2']=df_t.loc[:,'Hour'].apply(hourslice2)   \n",
    "z = pd.get_dummies(df_t['hourslice2'], drop_first=True)\n",
    "df_t.loc[:,'season']=df_t.loc[:,'Month'].apply(season)   \n",
    "t = pd.get_dummies(df_t['season'], drop_first=True)   \n",
    "\n",
    "df_t = pd.concat([df_t, x,y,z,t], axis=1)\n",
    "\n",
    "df_t.loc[:,'Date_sec']=df_t['Dates'].apply(myfun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import holidays\n",
    "from datetime import date\n",
    "us_holidays = holidays.UnitedStates()  # or holidays.US()\n",
    "\n",
    "def isholiday(d) :\n",
    "    return(int(d in us_holidays))\n",
    "# example\n",
    "int(isholiday('2001-01-01 23:53:00'))\n",
    "\n",
    "df['Holiday']=df['Dates'].apply(isholiday)\n",
    "df_t['Holiday']=df_t['Dates'].apply(isholiday)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://sanfranciscopolice.org/police-district-maps\n",
    "# http://www.latlong.net/convert-address-to-lat-long.html\n",
    "\n",
    "PoliceStations_raw=pd.DataFrame(\n",
    "[['BAYVIEW'   ,-122.397981,37.729732],\n",
    " ['CENTRAL'   ,-122.409919,37.798732],\n",
    " ['INGLESIDE' ,-122.446215,37.724676],\n",
    " ['MISSION'   ,-122.422005,37.762849],\n",
    " ['NORTHERN'  ,-122.432467,37.780186],\n",
    " ['PARK'      ,-122.455287,37.767797],\n",
    " ['RICHMOND'  ,-122.464467,37.779928],\n",
    " ['SOUTHERN'  ,-122.389412,37.772380],\n",
    " ['TARAVAL'   ,-122.481500,37.743733],\n",
    " ['TENDERLOIN',-122.412899,37.783674]],columns=['PdDistrict','XX','YY'])\n",
    "PoliceStations_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df  =pd.merge(df  ,PoliceStations_raw,on='PdDistrict',how='left')\n",
    "df_t=pd.merge(df_t,PoliceStations_raw,on='PdDistrict',how='left')\n",
    "\n",
    "#df['Pd_Dist']=( (df['X']-df['XX']) **2 + (df['Y']-df['YY']) ** 2)\n",
    "df.head()\n",
    "# be careful pd.merge is resetting dtypes !!!!!!!\n",
    "df.dtypes\n",
    "df['Category'] = df_raw['Category'].astype('category')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Pd_Dist']=( (df['X']-df['XX']) **2 + (df['Y']-df['YY']) ** 2)\n",
    "df['Pd_Dist']=np.sqrt(df['Pd_Dist'])\n",
    "\n",
    "df_t['Pd_Dist']=( (df_t['X']-df_t['XX']) **2 + (df_t['Y']-df_t['YY']) ** 2)\n",
    "df_t['Pd_Dist']=np.sqrt(df_t['Pd_Dist'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize test data with training data scaling !!!!! very important !!!! (easy mistake)\n",
    "\n",
    "def norm_01(df1,df2):\n",
    "    return( ( df1 - df1.min()) / (df1.max() - df1.min()) , ( df2 - df1.min()) / (df1.max() - df1.min()) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Xnorm'],df_t['Xnorm']=norm_01(df['X'],df_t['X'])\n",
    "df['Ynorm'],df_t['Ynorm']=norm_01(df['Y'],df_t['Y'])\n",
    "df['Hournorm'],df_t['Hournorm']=norm_01(df['Hour'],df_t['Hour'])\n",
    "df['Date_secnorm'],df_t['Date_secnorm']=norm_01(df['Date_sec'],df_t['Date_sec'])\n",
    "df['Pd_Distnorm'],df_t['Pd_Distnorm']= norm_01(df['Pd_Dist'],df_t['Pd_Dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding Address Features\n",
    "df_a=df.loc[:,'Address']\n",
    "df_t_a = df_t.loc[:,'Address']\n",
    "\n",
    "\n",
    "df['AV']=df_a.apply(lambda x: int(' AV' in x))\n",
    "df['BL']=df_a.apply(lambda x: int(' BL' in x))\n",
    "df['CR']=df_a.apply(lambda x: int(' CR' in x))\n",
    "df['CT']=df_a.apply(lambda x: int(' CT' in x))\n",
    "df['DR']=df_a.apply(lambda x: int(' DR' in x))\n",
    "df['BL']=df_a.apply(lambda x: int(' BL' in x))\n",
    "df['LN']=df_a.apply(lambda x: int(' LN' in x))\n",
    "df['PL']=df_a.apply(lambda x: int(' PL' in x))\n",
    "df['PZ']=df_a.apply(lambda x: int(' PZ' in x))\n",
    "df['RD']=df_a.apply(lambda x: int(' RD' in x))\n",
    "df['TR']=df_a.apply(lambda x: int(' TR' in x))\n",
    "df['HWY']=df_a.apply(lambda x: int((' HY' in x) or ('HWY' in x)) )\n",
    "df['WAY']=df_a.apply(lambda x: int((' WY' in x) or ('WAY' in x)) )\n",
    "#i took out 'ST' because everything not above contains ST\n",
    "\n",
    "df['IsIntersect'] = df_a.apply(lambda x: int('/' in x))\n",
    "\n",
    "# same for test set\n",
    "\n",
    "df_t['AV'] =df_t_a.apply(lambda x: int(' AV' in x))\n",
    "df_t['BL'] =df_t_a.apply(lambda x: int(' BL' in x))\n",
    "df_t['CR'] =df_t_a.apply(lambda x: int(' CR' in x))\n",
    "df_t['CT'] =df_t_a.apply(lambda x: int(' CT' in x))\n",
    "df_t['DR'] =df_t_a.apply(lambda x: int(' DR' in x))\n",
    "df_t['BL'] =df_t_a.apply(lambda x: int(' BL' in x))\n",
    "df_t['LN'] =df_t_a.apply(lambda x: int(' LN' in x))\n",
    "df_t['PL'] =df_t_a.apply(lambda x: int(' PL' in x))\n",
    "df_t['PZ'] =df_t_a.apply(lambda x: int(' PZ' in x))\n",
    "df_t['RD'] =df_t_a.apply(lambda x: int(' RD' in x))\n",
    "df_t['TR'] =df_t_a.apply(lambda x: int(' TR' in x))\n",
    "df_t['HWY']=df_t_a.apply(lambda x: int((' HY' in x) or ('HWY' in x)) )\n",
    "df_t['WAY']=df_t_a.apply(lambda x: int((' WY' in x) or ('WAY' in x)) )\n",
    "#i took out 'ST' because everything not above contains ST\n",
    "\n",
    "df_t['IsIntersect'] = df_t_a.apply(lambda x: int('/' in x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# be careful when adding the address features to the validation set.\n",
    "# the validation set should have its features calculated in the same way than the test set \n",
    "# in version 4, we define the traindata and validdata at this stage, before calculating the logodds features\n",
    "# that explains the over-optimistic evaluation of the logloss in version 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "rows = random.sample(df.index, NObs//10)\n",
    "# rows1 = rows[:len(rows)//2]\n",
    "# rows2 = rows[len(rows)//2:]\n",
    "# validdata = df.ix[rows1]\n",
    "# testdata  = df.ix[rows2]\n",
    "\n",
    "validdata =df.ix[rows]\n",
    "# validdata =validdata.drop('Id',axis=1)\n",
    "\n",
    "traindata = df.drop(rows)\n",
    "#traindata=traindata.drop('Id',axis=1)\n",
    "\n",
    "print(traindata.shape)\n",
    "print(validdata.shape)\n",
    "\n",
    "\n",
    "testdata = df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_a = traindata['Address']\n",
    "df_v_a= validdata['Address']\n",
    "\n",
    "address_train=pd.DataFrame(sorted(df_a.unique()),columns=['Address'])\n",
    "address_valid=pd.DataFrame(sorted(df_v_a.unique()),columns=['Address'])\n",
    "address_test =pd.DataFrame(sorted(df_t_a.unique()),columns=['Address'])\n",
    "\n",
    "\n",
    "print('number of addresses in train set %d' % len(address_train))\n",
    "print('number of addresses in valid set %d' % len(address_valid))\n",
    "print('number of addresses in test  set %d' % len(address_test))\n",
    "\n",
    "# categories=sorted(df[\"Category\"].unique())\n",
    "C_counts=traindata.groupby([\"Category\"]).size()\n",
    "N_obs_train=len(traindata)\n",
    "print(sum(C_counts))\n",
    "print(len(traindata))\n",
    "# A_C_counts=df.groupby([\"Address\",\"Category\"]).size()\n",
    "\n",
    "A_counts=traindata.groupby([\"Address\"]).size()\n",
    "A_counts=pd.DataFrame(A_counts)\n",
    "A_counts.columns=['count']\n",
    "A_counts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_address_valid=pd.merge(address_valid,A_counts,left_on='Address',right_index=True,how='left',indicator=True)\n",
    "print('number of addresses in test set not present in the train set %d' % len(check_address_valid[check_address_valid['_merge']=='left_only']))\n",
    "# 1563 new addresses in the test set, how many observations is that ?\n",
    "check_address_valid\n",
    "\n",
    "check_address_test=pd.merge(address_test,A_counts,left_on='Address',right_index=True,how='left',indicator=True)\n",
    "print('number of addresses in test set not present in the train set %d' % len(check_address_test[check_address_test['_merge']=='left_only']))\n",
    "# 1563 new addresses in the test set, how many observations is that ?\n",
    "check_address_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "address_test.head()\n",
    "A_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.merge(traindata,A_counts,left_on='Address',how='left',right_index=True)\n",
    "df1['one']=1\n",
    "\n",
    "table = pd.pivot_table(df1, values='one',index=['Address'],\n",
    "                 columns=['Category'], fill_value=0, aggfunc=np.sum)\n",
    "Total=table.sum(axis=1)\n",
    "\n",
    "def myfun(v):\n",
    "    w=v.astype(float)\n",
    "    return(np.divide(w,Total))\n",
    "table=table.apply(myfun)\n",
    "table\n",
    "table.columns=[\"proba_\"+str(x) for x in range(len(table.columns))]\n",
    "\n",
    "df2=pd.merge(df1,table,left_on='Address',how='left',right_index=True).drop(['one'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table.loc['Default',:]=np.array(C_counts/N_obs_train)\n",
    "print(sum(table.loc['Default',:]))\n",
    "table.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_t_1 = pd.merge(df_t,check_address,on='Address',how='left')\n",
    "df_t_1['Address'][df_t_1['_merge']=='left_only']='Default'\n",
    "# number of obs in the test set with Default address\n",
    "print(sum((df_t_1['Address']=='Default').astype(int)))\n",
    "\n",
    "df_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_t_2=pd.merge(df_t_1,table,left_on='Address',how='left',right_index=True)\n",
    "print(df_t_2['count'].loc[0])\n",
    "print(A_counts.loc['2000 Block of THOMAS AV'])\n",
    "\n",
    "# set count to 1 for addresses which are present in test set, but not in the training set\n",
    "\n",
    "# xxx=df_t_2[df_t_2['Address']=='Default']\n",
    "# df_t_2['count'][df_t_2['Address']=='Default']\n",
    "df_t_2['count'][df_t_2['Address']=='Default']=1 \n",
    "\n",
    "df2   ['count']=df2.loc[:,'count']/N_obs_train\n",
    "df_t_2['count']=df_t_2.loc [:,'count']/N_obs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# leaving only normalized variables in the training set\n",
    "df=df2.drop(['Id','Dates','Date_sec','Hour','season','Descript','PdDistrict','Resolution','Address','X','Y','XX','YY','hourslice2','DayOfWeek','Pd_Dist',\n",
    "            'spring','summer','winter'],axis=1) \n",
    "# leaving only normalized variables in the test set\n",
    "df_t=df_t_2.drop(['Id','_merge','Dates','Date_sec','Hour','season','PdDistrict','Address','X','Y','XX','YY','hourslice2','DayOfWeek','Pd_Dist',\n",
    "                 'spring','summer','winter'],axis=1) \n",
    "print(len(df_t.columns))\n",
    "print(len(df.columns))\n",
    "# the 1 difference in column length is because train set includes Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_counts.head()\n",
    "for x in df.columns: print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NObs = df.shape[0]\n",
    "NObs//10\n",
    "87798%128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "rows = random.sample(df.index, NObs//10)\n",
    "# rows1 = rows[:len(rows)//2]\n",
    "# rows2 = rows[len(rows)//2:]\n",
    "# validdata = df.ix[rows1]\n",
    "# testdata  = df.ix[rows2]\n",
    "\n",
    "validdata =df.ix[rows]\n",
    "# validdata =validdata.drop('Id',axis=1)\n",
    "\n",
    "traindata = df.drop(rows)\n",
    "#traindata=traindata.drop('Id',axis=1)\n",
    "\n",
    "print(traindata.shape)\n",
    "print(validdata.shape)\n",
    "\n",
    "\n",
    "testdata = df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minidf= traindata.loc[1:5,:]\n",
    "# minidf['hourslice2']\n",
    "minidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = minidf.columns\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_variables = traindata.shape[1]-1 # substract 1 because we will drop the target variable later\n",
    "num_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_Category=df['Category'].cat.categories.shape[0]\n",
    "num_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Categories=np.array(traindata.loc[:,'Category'].cat.categories)\n",
    "Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare data for TensorFlow\n",
    "\n",
    "num_var = num_variables   # 85\n",
    "num_labels = num_Category # 39 categories\n",
    "\n",
    "train_dataset = np.float32(np.array(traindata.drop(['Category'],axis=1)))\n",
    "train_labels = traindata.loc[:,'Category']\n",
    "train_labels= np.array(pd.get_dummies(train_labels.cat.rename_categories(np.arange(0,num_labels)) ))\n",
    "\n",
    "valid_dataset = np.float32(np.array(validdata.drop(['Category'],axis=1)))\n",
    "valid_labels = validdata.loc[:,'Category']\n",
    "valid_labels= np.array(pd.get_dummies(valid_labels.cat.rename_categories(np.arange(0,num_labels)) ))\n",
    "\n",
    "test_dataset = np.float32(np.array(df_t))\n",
    "# test_labels = testdata.loc[:,'Category']\n",
    "# test_labels= np.array(pd.get_dummies(test_labels.cat.rename_categories(np.arange(0,num_labels)) ))\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape)\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding regularization to the 1 hidden layer network\n",
    "graph1 = tf.Graph()\n",
    "batch_size = 128\n",
    "\n",
    "num_steps=13001 #6501\n",
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now() \n",
    "\n",
    "def define_and_run_batch(beta):\n",
    "    \n",
    "    num_RELU = 1024\n",
    "    \n",
    "    with graph1.as_default():\n",
    "\n",
    "      # Input data. For the training data, we use a placeholder that will be fed\n",
    "      # at run time with a training minibatch.\n",
    "      tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                        shape=(batch_size, num_var)) # remplace batch_size par None\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "      tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    \n",
    "      # in Kaggle competitions, we don't know the true labels of the test set\n",
    "      tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "      # Variables.\n",
    "      weights_RELU = tf.Variable(\n",
    "        tf.truncated_normal([num_var, num_RELU],stddev=0.1))\n",
    "        \n",
    "      # print(tf.shape(weights_RELU) )   \n",
    "      #biases_RELU = tf.Variable(tf.zeros([num_RELU]))\n",
    "      biases_RELU = tf.Variable(tf.random_normal([num_RELU],stddev=0.1))  \n",
    "        \n",
    "      weights_layer1 = tf.Variable(\n",
    "        tf.truncated_normal([num_RELU, num_labels],stddev=0.1))\n",
    "      #biases_layer1 = tf.Variable(tf.zeros([num_labels]))\n",
    "      biases_layer1 = tf.Variable(tf.random_normal([num_labels],stddev=0.1))\n",
    "  \n",
    "      # Training computation.\n",
    "      logits_RELU = tf.matmul(tf_train_dataset, weights_RELU) + biases_RELU\n",
    "      RELU_vec = tf.nn.relu(logits_RELU)\n",
    "      logits_layer = tf.matmul(RELU_vec, weights_layer1) + biases_layer1                  \n",
    "      # loss = tf.reduce_mean(\n",
    "      #        tf.nn.softmax_cross_entropy_with_logits(logits_layer, tf_train_labels))\n",
    "      cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits_layer, tf_train_labels,name=\"cross_entropy\")\n",
    "      l2reg = tf.reduce_sum(tf.square(weights_RELU))+tf.reduce_sum(tf.square(weights_layer1))\n",
    "      \n",
    "      loss = tf.reduce_mean(cross_entropy+beta*l2reg)\n",
    "      logloss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "  # Optimizer.\n",
    "      optimizer = tf.train.GradientDescentOptimizer(0.3).minimize(loss)\n",
    "  \n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(logits_layer)\n",
    "      \n",
    "      valid_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu((tf.matmul(tf_valid_dataset, weights_RELU) + biases_RELU)),weights_layer1)+biases_layer1)\n",
    "        \n",
    "      # in Kaggle competitions, we don't know the true labels of the test set     \n",
    "      test_prediction =tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu((tf.matmul(tf_test_dataset, weights_RELU) + biases_RELU)),weights_layer1)+biases_layer1)\n",
    "                         \n",
    "    with tf.Session(graph=graph1) as session:\n",
    " \n",
    "      tf.initialize_all_variables().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        \n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        # Generate a minibatch. \n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        \n",
    "        batch_labels = train_labels[offset:(offset + batch_size)]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #\n",
    "        if (step==num_steps-1):\n",
    "            _, l, predictions_train,predictions_test = session.run(\n",
    "              [optimizer, logloss,train_prediction,test_prediction], feed_dict=feed_dict)\n",
    "        else:\n",
    "            _, l, predictions_train = session.run(\n",
    "              [optimizer, logloss,train_prediction], feed_dict=feed_dict)\n",
    "            \n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions_train, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "      \n",
    "      # test_acc = accuracy(test_prediction.eval(), test_labels)\n",
    "      # print(\"Test accuracy: %.1f%%\" % test_acc)\n",
    "\n",
    "      print('loss=%s' % l)\n",
    "        \n",
    "    x = datetime.datetime.now() - startTime\n",
    "    print(x)\n",
    "    return(predictions_test)\n",
    "    \n",
    "    \n",
    "RES=define_and_run_batch(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 layer network\n",
    "\n",
    "graph1 = tf.Graph()\n",
    "batch_size = 128\n",
    "\n",
    "num_steps=39001 #6501\n",
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now() \n",
    "\n",
    "def define_and_run_batch_4_layer():\n",
    "    \n",
    "    \n",
    "\n",
    "    import math as math\n",
    "\n",
    "    initial_learning_rate_value = 0.5\n",
    "    beta1 = 0.001\n",
    "    beta2 = 0.001\n",
    "    beta3 = 0.001\n",
    "    beta4 = 0.001\n",
    "    beta5 = 0.001\n",
    "\n",
    "    graph2 = tf.Graph()\n",
    "    with graph2.as_default():\n",
    "\n",
    "       # Input data. For the training data, we use a placeholder that will be fed\n",
    "       # at run time with a training minibatch.\n",
    "       tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, num_var))\n",
    "       tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        \n",
    "       tf_valid_dataset = tf.constant(valid_dataset)\n",
    "       tf_test_dataset = tf.constant(test_dataset)    \n",
    "    \n",
    "       # learning rate decay\n",
    "       global_step = tf.Variable(0)\n",
    "       learning_rate = tf.train.exponential_decay(initial_learning_rate_value, global_step, 1, 0.9999)\n",
    "\n",
    "       # Hidden layer 1\n",
    "       h1_size = 2048  \n",
    "       weights_h1 = tf.Variable(tf.truncated_normal([num_var, h1_size], stddev=math.sqrt(2.0/(num_var))))\n",
    "       biases_h1 = tf.Variable(tf.zeros([h1_size]))\n",
    "       h1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_h1) + biases_h1)\n",
    "\n",
    "       # Hidden layer 2\n",
    "       h2_size = 1024\n",
    "       weights_h2 = tf.Variable(tf.truncated_normal([h1_size, h2_size], stddev=math.sqrt(2.0/h1_size)))\n",
    "       biases_h2 = tf.Variable(tf.zeros([h2_size]))\n",
    "       h2 = tf.nn.relu(tf.matmul(h1, weights_h2) + biases_h2)\n",
    "\n",
    "       # Hidden layer 3\n",
    "       h3_size = 512\n",
    "       weights_h3 = tf.Variable(tf.truncated_normal([h2_size, h3_size], stddev=math.sqrt(2.0/h2_size)))\n",
    "       biases_h3 = tf.Variable(tf.zeros([h3_size]))\n",
    "       h3 = tf.nn.relu(tf.matmul(h2, weights_h3) + biases_h3)\n",
    "\n",
    "       # Hidden layer 4\n",
    "       h4_size = 256\n",
    "       weights_h4 = tf.Variable(tf.truncated_normal([h3_size, h4_size], stddev=math.sqrt(2.0/h3_size)))\n",
    "       biases_h4 = tf.Variable(tf.zeros([h4_size]))\n",
    "       h4 = tf.nn.relu(tf.matmul(h3, weights_h4) + biases_h4)\n",
    "\n",
    "       # Output layer\n",
    "       weights_o = tf.Variable(tf.truncated_normal([h4_size, num_labels], stddev=math.sqrt(2.0/h4_size)))\n",
    "       biases_o = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "       # Training computation.\n",
    "       logits = tf.matmul(h4, weights_o) + biases_o\n",
    "       # loss = tf.reduce_mean(\n",
    "       #     tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + ((beta1 * tf.nn.l2_loss(weights_h1)) + (beta2 * tf.nn.l2_loss(weights_h2)) \n",
    "       #        + (beta3 * tf.nn.l2_loss(weights_h3)) + (beta4 * tf.nn.l2_loss(weights_h4)) + (beta5 * tf.nn.l2_loss(weights_o)))\n",
    "       \n",
    "       cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels,name=\"cross_entropy\")\n",
    "       logloss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "       loss = logloss + ((beta1 * tf.nn.l2_loss(weights_h1)) + (beta2 * tf.nn.l2_loss(weights_h2)) + (beta3 * tf.nn.l2_loss(weights_h3)) \n",
    "                         + (beta4 * tf.nn.l2_loss(weights_h4)) + (beta5 * tf.nn.l2_loss(weights_o)))\n",
    "       \n",
    "    \n",
    "       # Optimizer.\n",
    "       optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "       # Predictions for the training, validation, and test data.\n",
    "       train_h1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_h1) + biases_h1)\n",
    "       train_h2 = tf.nn.relu(tf.matmul(train_h1, weights_h2) + biases_h2)\n",
    "       train_h3 = tf.nn.relu(tf.matmul(train_h2, weights_h3) + biases_h3)\n",
    "       train_h4 = tf.nn.relu(tf.matmul(train_h3, weights_h4) + biases_h4)\n",
    "       train_logits = tf.matmul(train_h4, weights_o) + biases_o\n",
    "       train_prediction = tf.nn.softmax(train_logits)\n",
    "  \n",
    "       valid_h1 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_h1) + biases_h1)\n",
    "       valid_h2 = tf.nn.relu(tf.matmul(valid_h1, weights_h2) + biases_h2)\n",
    "       valid_h3 = tf.nn.relu(tf.matmul(valid_h2, weights_h3) + biases_h3)\n",
    "       valid_h4 = tf.nn.relu(tf.matmul(valid_h3, weights_h4) + biases_h4)\n",
    "       valid_logits = tf.matmul(valid_h4, weights_o) + biases_o\n",
    "       valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    \n",
    "       test_h1 = tf.nn.relu(tf.matmul(tf_test_dataset, weights_h1) + biases_h1)\n",
    "       test_h2 = tf.nn.relu(tf.matmul(test_h1, weights_h2) + biases_h2)\n",
    "       test_h3 = tf.nn.relu(tf.matmul(test_h2, weights_h3) + biases_h3)\n",
    "       test_h4 = tf.nn.relu(tf.matmul(test_h3, weights_h4) + biases_h4)\n",
    "       test_logits = tf.matmul(test_h4, weights_o) + biases_o\n",
    "       test_prediction = tf.nn.softmax(test_logits)\n",
    "  \n",
    "        \n",
    "   \n",
    "\n",
    "# executing the graph     \n",
    "        \n",
    "        \n",
    "    with tf.Session(graph=graph2) as session:\n",
    " \n",
    "      tf.initialize_all_variables().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        \n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        # Generate a minibatch. \n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        \n",
    "        batch_labels = train_labels[offset:(offset + batch_size)]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #\n",
    "        if (step==num_steps-1):\n",
    "            _, l, predictions_train,predictions_test = session.run(\n",
    "              [optimizer, logloss,train_prediction,test_prediction], feed_dict=feed_dict)\n",
    "        else:\n",
    "            _, l, predictions_train = session.run(\n",
    "              [optimizer, logloss,train_prediction], feed_dict=feed_dict)\n",
    "            \n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions_train, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "      \n",
    "      # test_acc = accuracy(test_prediction.eval(), test_labels)\n",
    "      # print(\"Test accuracy: %.1f%%\" % test_acc)\n",
    "\n",
    "      print('loss=%s' % l)\n",
    "        \n",
    "    x = datetime.datetime.now() - startTime\n",
    "    print(x)\n",
    "    return(predictions_test)\n",
    "    \n",
    "    \n",
    "RES=define_and_run_batch_4_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = np.float32(np.array(traindata.drop(['Category'],axis=1)))\n",
    "train_labels = traindata.loc[:,'Category']\n",
    "train_labels=train_labels.cat.rename_categories(np.arange(0,num_labels))\n",
    "train_labels\n",
    "pd.get_dummies(train_labels).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use sklearn one-hot-encoder only if using sklearn functions\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### XGBOOST ######\n",
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now() \n",
    "\n",
    "import xgboost as xgb\n",
    "data_train   = np.array(traindata.drop('Category',axis=1))\n",
    "labels_train = np.array(traindata['Category'].cat.codes)\n",
    "\n",
    "data_valid   = np.array(validdata.drop('Category',axis=1))\n",
    "labels_valid = np.array(validdata['Category'].cat.codes)\n",
    "\n",
    "weights_train = np.ones(len(labels_train))\n",
    "weights_valid  = np.ones(len(labels_valid ))\n",
    "\n",
    "dtrain = xgb.DMatrix( data_train, label=labels_train,weight = weights_train)\n",
    "dvalid  = xgb.DMatrix( data_valid , label=labels_valid ,weight = weights_valid )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param = {'bst:max_depth':5, 'bst:eta':0.5, # eta [default=0.3]\n",
    "         #'min_child_weight':1,'gamma':0,'subsample':1,'colsample_bytree':1,'scale_pos_weight':0, # default\n",
    "         # max_delta_step:0 # default\n",
    "         'min_child_weight':6,'scale_pos_weight':0.1, 'max_delta_step':1\n",
    "         'subsample':0.8,'colsample_bytree':0.8,\n",
    "         'silent':1, 'objective':'multi:softprob' }\n",
    "\n",
    "\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'mlogloss'\n",
    "param['lambda'] = 1\n",
    "param['num_class']=39\n",
    "\n",
    "# evallist  = [(dvalid,'eval'),(dtrain,'train')] # if there is a validation set\n",
    "evallist  = [(dtrain,'train')]                   # if there is no validation set\n",
    "\n",
    "plst = param.items()\n",
    "plst += [('eval_metric', 'ams@0')]\n",
    "\n",
    "num_round = 10\n",
    "bst = xgb.train( plst, dtrain, num_round, evallist ) # early_stopping_rounds=10 # when there is a validation set\n",
    "\n",
    "bst.save_model('0001.model')\n",
    "\n",
    "# dump model\n",
    "bst.dump_model('dump.raw.txt')\n",
    "# dump model with feature map\n",
    "# bst.dump_model('dump.raw.txt','featmap.txt')\n",
    "\n",
    "x = datetime.datetime.now() - startTime\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minidf['Category'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "xgb.plot_importance(bst)\n",
    "xgb.plot_tree(bst, num_trees=2)\n",
    "#xgb.to_graphviz(bst, num_trees=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test   = np.array(df_t)\n",
    "\n",
    "dtest = xgb.DMatrix( data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predXGB = bst.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submit=pd.read_csv('/Users/francois-guillaume.rideau/Documents/Kaggle/Kaggle-SF/sampleSubmission.csv',dtype=float)\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submit.shape\n",
    "type(df_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range (1,40): \n",
    "    df_submit[df_submit.columns[i]]=predXGB[:,i-1] # for XGBoost\n",
    "    # df_submit[df_submit.columns[i]]=RES[:,i-1]   # for TensorFlow\n",
    "df_submit['Id']=df_submit['Id'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '/Users/francois-guillaume.rideau/Documents/Kaggle/Kaggle-SF/submitXGB5.csv'\n",
    "df_submit.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_verify=pd.read_csv(filename,dtype=float)\n",
    "df_verify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z=df_verify.describe()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking if the mean of predicted probabilities match with the distribution in the training set\n",
    "zz=z.loc['mean',:].sort_values(ascending=False)\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# distribution of Category in the training set\n",
    "df_raw['Category'].value_counts()/877982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predXGB_train = bst.predict(dtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predXGB_train=pd.DataFrame(predXGB_train)\n",
    "predXGB_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predXGB_train.columns=df_raw['Category'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z=predXGB_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.ix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw['Voie']='Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_raw['Voie']=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=pd.DataFrame([[0,'CENTRAL'],[1,'TARAVAL'],[3,'CENTRAL'],[2,'BAYVIEW']])\n",
    "df1.columns = ['Index','PdDistrict']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sqrt(880000*39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
