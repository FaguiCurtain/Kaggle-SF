{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_moons(10000, noise=0.20)\n",
    "\n",
    "# Can't believe I'm doing it this way, but join doesn't work\n",
    "# on numpy strings and I'm on a plane unable to lookup the\n",
    "# right way to join a column to a matrix and output as CSV.\n",
    "for x_i,y_i in zip(X,y):\n",
    "    output = ''\n",
    "    output += str(y_i)\n",
    "    for j in range(0,len(x_i)):\n",
    "        output += ','\n",
    "        output += str(x_i[j])\n",
    "    # print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NObs =X.shape[0]\n",
    "\n",
    "traindata=X[0:NObs/2,:]\n",
    "validdata=X[NObs/2+1:NObs*3/4,:]\n",
    "testdata=X[NObs*3/4+1:,:]\n",
    "\n",
    "train_labels=pd.DataFrame(y[0:NObs/2])\n",
    "valid_labels=pd.DataFrame(y[NObs/2+1:NObs*3/4])\n",
    "\n",
    "test_labels=pd.DataFrame(y[NObs*3/4+1:])\n",
    "\n",
    "train_labels.columns = ['label']\n",
    "valid_labels.columns = ['label']\n",
    "test_labels.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (5000, 2), (5000, 2))\n",
      "('Validation set', (2499, 2), (2499, 2))\n",
      "('Test set', (2499, 2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare data for TensorFlow\n",
    "\n",
    "num_var = 2\n",
    "num_labels = 2 # 39 categories\n",
    "\n",
    "train_dataset = np.float32(np.array(traindata))\n",
    "N_obs_train=len(train_dataset)\n",
    "\n",
    "valid_dataset = np.float32(np.array(validdata))\n",
    "\n",
    "test_dataset = np.float32(np.array(testdata))\n",
    "\n",
    "train_labels= np.array(pd.get_dummies(train_labels['label'].astype('category').cat.rename_categories(np.arange(0,num_labels)) ))\n",
    "valid_labels= np.array(pd.get_dummies(valid_labels['label'].astype('category').cat.rename_categories(np.arange(0,num_labels)) ))\n",
    "test_labels= np.array(pd.get_dummies ( test_labels['label'].astype('category').cat.rename_categories(np.arange(0,num_labels)) ))\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape)\n",
    "\n",
    "test_dataset.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def baseline_logloss(hotmatrix): #input is a hot-encoded sparse matrix, one 1 only per row, rest is 0\n",
    "    nobs = len(hotmatrix)\n",
    "    temp = hotmatrix.sum(axis=0)/nobs\n",
    "    return(-sum(np.multiply(temp,np.log(temp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 0.687988\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 60.7%\n",
      "Minibatch loss at step 50: 0.342020\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 100: 0.308745\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 150: 0.254597\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.3%\n",
      "0:00:00.761320\n",
      "Validation Logloss =0.274545674243\n",
      "Test       Logloss =0.283503139714\n"
     ]
    }
   ],
   "source": [
    "# Adding regularization to the 1 hidden layer network\n",
    "graph1 = tf.Graph()\n",
    "batch_size = 128\n",
    "\n",
    "epoch_size  = N_obs_train / batch_size\n",
    "num_steps= 5 * epoch_size\n",
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now() \n",
    "\n",
    "def define_and_run_batch(beta):\n",
    "    \n",
    "    num_RELU = 10\n",
    "    \n",
    "    with graph1.as_default():\n",
    "      \n",
    "      keep_prob = tf.placeholder(tf.float32)\n",
    "      \n",
    "      # Input data. For the training data, we use a placeholder that will be fed\n",
    "      # at run time with a training minibatch.\n",
    "      tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                        shape=(batch_size, num_var)) # remplace batch_size par None\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "      tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    \n",
    "      # in Kaggle competitions, we don't know the true labels of the test set\n",
    "      tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "      # Variables.\n",
    "      weights_RELU = tf.Variable(\n",
    "        tf.truncated_normal([num_var, num_RELU],stddev=0.1))\n",
    "        \n",
    "      # print(tf.shape(weights_RELU) )   \n",
    "      #biases_RELU = tf.Variable(tf.zeros([num_RELU]))\n",
    "      biases_RELU = tf.Variable(tf.random_normal([num_RELU],stddev=0.1))  \n",
    "        \n",
    "      weights_layer1 = tf.Variable(\n",
    "        tf.truncated_normal([num_RELU, num_labels],stddev=0.1))\n",
    "      #biases_layer1 = tf.Variable(tf.zeros([num_labels]))\n",
    "      biases_layer1 = tf.Variable(tf.random_normal([num_labels],stddev=0.1))\n",
    "  \n",
    "      # Training computation.\n",
    "      logits_RELU = tf.matmul(tf_train_dataset, weights_RELU) + biases_RELU\n",
    "      RELU_vec = tf.nn.relu(logits_RELU)\n",
    "      RELU_vec_drop = tf.nn.dropout(RELU_vec, keep_prob)\n",
    "    \n",
    "      logits_layer = tf.matmul(RELU_vec_drop, weights_layer1) + biases_layer1                  \n",
    "      # loss = tf.reduce_mean(\n",
    "      #        tf.nn.softmax_cross_entropy_with_logits(logits_layer, tf_train_labels))\n",
    "      cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits_layer, tf_train_labels,name=\"cross_entropy\")\n",
    "      l2reg = tf.reduce_sum(tf.square(weights_RELU))+tf.reduce_sum(tf.square(weights_layer1))\n",
    "      \n",
    "      loss = tf.reduce_mean(cross_entropy+beta*l2reg)\n",
    "      logloss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "  # Optimizer.\n",
    "      optimizer = tf.train.GradientDescentOptimizer(0.3).minimize(loss)\n",
    "  \n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(logits_layer)\n",
    "      \n",
    "      valid_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu((tf.matmul(tf_valid_dataset, weights_RELU) + biases_RELU)),weights_layer1)+biases_layer1)\n",
    "        \n",
    "      # in Kaggle competitions, we don't know the true labels of the test set     \n",
    "      test_prediction =tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu((tf.matmul(tf_test_dataset, weights_RELU) + biases_RELU)),weights_layer1)+biases_layer1)\n",
    "                         \n",
    "    with tf.Session(graph=graph1) as session:\n",
    " \n",
    "      tf.initialize_all_variables().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        \n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        # Generate a minibatch. \n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        \n",
    "        batch_labels = train_labels[offset:(offset + batch_size)]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels,\n",
    "                    keep_prob:1.0}\n",
    "        \n",
    "        #\n",
    "        if (step==num_steps-1):\n",
    "            _, l, predictions_train,predictions_test,predictions_valid = session.run(\n",
    "              [optimizer, logloss,train_prediction,test_prediction,valid_prediction], feed_dict=feed_dict)\n",
    "        else:\n",
    "            _, l, predictions_train = session.run(\n",
    "              [optimizer, logloss,train_prediction], feed_dict=feed_dict)\n",
    "            \n",
    "        if (step % 50 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions_train, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "      \n",
    "      # test_acc = accuracy(test_prediction.eval(), test_labels)\n",
    "      # print(\"Test accuracy: %.1f%%\" % test_acc)\n",
    "\n",
    "      \n",
    "        \n",
    "    x = datetime.datetime.now() - startTime\n",
    "    print(x)\n",
    "    return(predictions_test,predictions_valid,predictions_train)\n",
    "    \n",
    "    \n",
    "RES,RES_v,RES_tr=define_and_run_batch(0.001)\n",
    "N_obs_valid = validdata.shape[0]\n",
    "N_obs_test  =  testdata.shape[0]\n",
    "logloss_valid=-sum(sum(np.multiply(valid_labels,np.log(RES_v))))/N_obs_valid\n",
    "logloss_test =-sum(sum(np.multiply( test_labels,np.log(RES  ))))/N_obs_test\n",
    "print(\"Validation Logloss =%s\" % logloss_valid)\n",
    "print(\"Test       Logloss =%s\" % logloss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 0.685639\n",
      "Minibatch accuracy: 49.2%\n",
      "Validation accuracy: 64.1%\n",
      "0:00:00.687200\n",
      "Validation Logloss =0.197863387164\n",
      "Test       Logloss =0.198305062552\n"
     ]
    }
   ],
   "source": [
    "# 4 layer network\n",
    "\n",
    "graph1 = tf.Graph()\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "epoch_size  = N_obs_train / batch_size\n",
    "num_steps= 2 * epoch_size #6501\n",
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now() \n",
    "\n",
    "def define_and_run_batch_4_layer():\n",
    "    \n",
    "    \n",
    "\n",
    "    import math as math\n",
    "\n",
    "    initial_learning_rate_value = 0.5\n",
    "    beta1 = 0.001\n",
    "    beta2 = 0.001\n",
    "    beta3 = 0.001\n",
    "    beta4 = 0.001\n",
    "    beta5 = 0.001\n",
    "\n",
    "    graph2 = tf.Graph()\n",
    "    with graph2.as_default():\n",
    "\n",
    "       # Input data. For the training data, we use a placeholder that will be fed\n",
    "       # at run time with a training minibatch.\n",
    "       tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, num_var))\n",
    "       tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        \n",
    "       tf_valid_dataset = tf.constant(valid_dataset)\n",
    "       tf_test_dataset = tf.constant(test_dataset)    \n",
    "    \n",
    "       # learning rate decay\n",
    "       global_step = tf.Variable(0)\n",
    "       learning_rate = tf.train.exponential_decay(initial_learning_rate_value, global_step, 1, 0.9999)\n",
    "\n",
    "       # Hidden layer 1\n",
    "       h1_size = 32  \n",
    "       weights_h1 = tf.Variable(tf.truncated_normal([num_var, h1_size], stddev=math.sqrt(2.0/(num_var))))\n",
    "       biases_h1 = tf.Variable(tf.zeros([h1_size]))\n",
    "       h1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_h1) + biases_h1)\n",
    "\n",
    "       # Hidden layer 2\n",
    "       h2_size = 16\n",
    "       weights_h2 = tf.Variable(tf.truncated_normal([h1_size, h2_size], stddev=math.sqrt(2.0/h1_size)))\n",
    "       biases_h2 = tf.Variable(tf.zeros([h2_size]))\n",
    "       h2 = tf.nn.relu(tf.matmul(h1, weights_h2) + biases_h2)\n",
    "\n",
    "       # Hidden layer 3\n",
    "       h3_size = 8\n",
    "       weights_h3 = tf.Variable(tf.truncated_normal([h2_size, h3_size], stddev=math.sqrt(2.0/h2_size)))\n",
    "       biases_h3 = tf.Variable(tf.zeros([h3_size]))\n",
    "       h3 = tf.nn.relu(tf.matmul(h2, weights_h3) + biases_h3)\n",
    "\n",
    "       # Hidden layer 4\n",
    "       h4_size = 4\n",
    "       weights_h4 = tf.Variable(tf.truncated_normal([h3_size, h4_size], stddev=math.sqrt(2.0/h3_size)))\n",
    "       biases_h4 = tf.Variable(tf.zeros([h4_size]))\n",
    "       h4 = tf.nn.relu(tf.matmul(h3, weights_h4) + biases_h4)\n",
    "\n",
    "       # Output layer\n",
    "       weights_o = tf.Variable(tf.truncated_normal([h4_size, num_labels], stddev=math.sqrt(2.0/h4_size)))\n",
    "       biases_o = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "       # Training computation.\n",
    "       logits = tf.matmul(h4, weights_o) + biases_o\n",
    "       # loss = tf.reduce_mean(\n",
    "       #     tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + ((beta1 * tf.nn.l2_loss(weights_h1)) + (beta2 * tf.nn.l2_loss(weights_h2)) \n",
    "       #        + (beta3 * tf.nn.l2_loss(weights_h3)) + (beta4 * tf.nn.l2_loss(weights_h4)) + (beta5 * tf.nn.l2_loss(weights_o)))\n",
    "       \n",
    "       cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels,name=\"cross_entropy\")\n",
    "       logloss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "       loss = logloss + ((beta1 * tf.nn.l2_loss(weights_h1)) + (beta2 * tf.nn.l2_loss(weights_h2)) + (beta3 * tf.nn.l2_loss(weights_h3)) \n",
    "                         + (beta4 * tf.nn.l2_loss(weights_h4)) + (beta5 * tf.nn.l2_loss(weights_o)))\n",
    "       \n",
    "    \n",
    "       # Optimizer.\n",
    "       optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "       # Predictions for the training, validation, and test data.\n",
    "       train_h1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_h1) + biases_h1)\n",
    "       train_h2 = tf.nn.relu(tf.matmul(train_h1, weights_h2) + biases_h2)\n",
    "       train_h3 = tf.nn.relu(tf.matmul(train_h2, weights_h3) + biases_h3)\n",
    "       train_h4 = tf.nn.relu(tf.matmul(train_h3, weights_h4) + biases_h4)\n",
    "       train_logits = tf.matmul(train_h4, weights_o) + biases_o\n",
    "       train_prediction = tf.nn.softmax(train_logits)\n",
    "  \n",
    "       valid_h1 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_h1) + biases_h1)\n",
    "       valid_h2 = tf.nn.relu(tf.matmul(valid_h1, weights_h2) + biases_h2)\n",
    "       valid_h3 = tf.nn.relu(tf.matmul(valid_h2, weights_h3) + biases_h3)\n",
    "       valid_h4 = tf.nn.relu(tf.matmul(valid_h3, weights_h4) + biases_h4)\n",
    "       valid_logits = tf.matmul(valid_h4, weights_o) + biases_o\n",
    "       valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    \n",
    "       test_h1 = tf.nn.relu(tf.matmul(tf_test_dataset, weights_h1) + biases_h1)\n",
    "       test_h2 = tf.nn.relu(tf.matmul(test_h1, weights_h2) + biases_h2)\n",
    "       test_h3 = tf.nn.relu(tf.matmul(test_h2, weights_h3) + biases_h3)\n",
    "       test_h4 = tf.nn.relu(tf.matmul(test_h3, weights_h4) + biases_h4)\n",
    "       test_logits = tf.matmul(test_h4, weights_o) + biases_o\n",
    "       test_prediction = tf.nn.softmax(test_logits)\n",
    "  \n",
    "        \n",
    "   \n",
    "\n",
    "# executing the graph     \n",
    "        \n",
    "        \n",
    "    with tf.Session(graph=graph2) as session:\n",
    " \n",
    "      tf.initialize_all_variables().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        \n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        # Generate a minibatch. \n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        \n",
    "        batch_labels = train_labels[offset:(offset + batch_size)]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #\n",
    "        if (step==num_steps-1):\n",
    "            _, l, predictions_train,predictions_test,predictions_valid = session.run(\n",
    "              [optimizer, logloss,train_prediction,test_prediction,valid_prediction], feed_dict=feed_dict)\n",
    "        else:\n",
    "            _, l, predictions_train = session.run(\n",
    "              [optimizer, logloss,train_prediction], feed_dict=feed_dict)\n",
    "            \n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions_train, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "      \n",
    "      # test_acc = accuracy(test_prediction.eval(), test_labels)\n",
    "      # print(\"Test accuracy: %.1f%%\" % test_acc)\n",
    "        \n",
    "    x = datetime.datetime.now() - startTime\n",
    "    print(x)\n",
    "    return(predictions_test,predictions_valid)\n",
    "    \n",
    "    \n",
    "    \n",
    "RES,RES_v=define_and_run_batch_4_layer()\n",
    "\n",
    "N_obs_valid = validdata.shape[0]\n",
    "N_obs_test  =  testdata.shape[0]\n",
    "logloss_valid=-sum(sum(np.multiply(valid_labels,np.log(RES_v))))/N_obs_valid\n",
    "logloss_test =-sum(sum(np.multiply( test_labels,np.log(RES  ))))/N_obs_test\n",
    "print(\"Validation Logloss =%s\" % logloss_valid)\n",
    "print(\"Test       Logloss =%s\" % logloss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692859152906\n",
      "0.692887029939\n"
     ]
    }
   ],
   "source": [
    "print(baseline_logloss(train_labels))\n",
    "print(baseline_logloss(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "93.7575030012\n",
      "93.1972789116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:3: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(RES_tr,train_labels))\n",
    "print(accuracy(RES_v ,valid_labels))\n",
    "print(accuracy(RES   , test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.771608</td>\n",
       "      <td>0.676851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.672482</td>\n",
       "      <td>0.620596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.270528</td>\n",
       "      <td>0.898430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.291727</td>\n",
       "      <td>0.819991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112167</td>\n",
       "      <td>-0.143066</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.906015</td>\n",
       "      <td>-0.342094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.939017</td>\n",
       "      <td>0.153691</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.845869</td>\n",
       "      <td>0.196277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.871419</td>\n",
       "      <td>-0.045443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.415073</td>\n",
       "      <td>0.170630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.911897</td>\n",
       "      <td>-0.555107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.167141</td>\n",
       "      <td>-0.450536</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.701332</td>\n",
       "      <td>-0.226512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.539611</td>\n",
       "      <td>-0.499616</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.212235</td>\n",
       "      <td>0.588568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.804473</td>\n",
       "      <td>-0.482031</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.626039</td>\n",
       "      <td>-0.248810</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.950911</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>false_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.768602</td>\n",
       "      <td>-0.282775</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.001561</td>\n",
       "      <td>0.075039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.644091</td>\n",
       "      <td>0.965015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.269232</td>\n",
       "      <td>-0.548240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.900681</td>\n",
       "      <td>0.467587</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.872895</td>\n",
       "      <td>0.718372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.453007</td>\n",
       "      <td>0.654407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.884851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.208977</td>\n",
       "      <td>0.111426</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.119292</td>\n",
       "      <td>-0.559978</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.862576</td>\n",
       "      <td>0.658330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.146609</td>\n",
       "      <td>-0.363577</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>0.641676</td>\n",
       "      <td>-0.851258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>-0.106102</td>\n",
       "      <td>0.662649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>-1.073335</td>\n",
       "      <td>0.236829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>0.053766</td>\n",
       "      <td>0.683436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>1.539834</td>\n",
       "      <td>-0.211039</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>0.210459</td>\n",
       "      <td>-0.184545</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>1.990283</td>\n",
       "      <td>-0.237843</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>0.860376</td>\n",
       "      <td>-0.333342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>0.988905</td>\n",
       "      <td>0.348300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>-0.962078</td>\n",
       "      <td>0.742595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>0.473551</td>\n",
       "      <td>1.166360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>1.795304</td>\n",
       "      <td>0.124235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>0.448075</td>\n",
       "      <td>0.341434</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>1.054459</td>\n",
       "      <td>-0.738213</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>0.109742</td>\n",
       "      <td>0.888796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>-0.113794</td>\n",
       "      <td>0.993061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>0.727077</td>\n",
       "      <td>-0.490295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>-0.764201</td>\n",
       "      <td>0.827592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>-0.324356</td>\n",
       "      <td>1.259565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>-1.075145</td>\n",
       "      <td>0.284090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>1.706838</td>\n",
       "      <td>-0.303140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>0.691590</td>\n",
       "      <td>-0.511156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>0.156617</td>\n",
       "      <td>0.246852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>0.679288</td>\n",
       "      <td>0.798198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>0.070084</td>\n",
       "      <td>0.020167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>2.000023</td>\n",
       "      <td>0.565411</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>false_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0.423511</td>\n",
       "      <td>-0.404103</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.163132</td>\n",
       "      <td>1.267795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0.649928</td>\n",
       "      <td>-0.674249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.925592</td>\n",
       "      <td>-0.755120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>true_pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2499 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X         Y  pred  label      class\n",
       "0    -0.771608  0.676851     0      0   true_neg\n",
       "1    -0.672482  0.620596     0      0   true_neg\n",
       "2     0.270528  0.898430     0      0   true_neg\n",
       "3     0.291727  0.819991     0      0   true_neg\n",
       "4     0.112167 -0.143066     1      1   true_pos\n",
       "5     0.906015 -0.342094     1      1   true_pos\n",
       "6     1.939017  0.153691     1      1   true_pos\n",
       "7     1.845869  0.196277     1      1   true_pos\n",
       "8     1.871419 -0.045443     1      1   true_pos\n",
       "9     0.415073  0.170630     1      1   true_pos\n",
       "10    0.911897 -0.555107     1      1   true_pos\n",
       "11    0.167141 -0.450536     1      1   true_pos\n",
       "12    0.701332 -0.226512     1      1   true_pos\n",
       "13    0.539611 -0.499616     1      1   true_pos\n",
       "14   -0.212235  0.588568     0      0   true_neg\n",
       "15    0.804473 -0.482031     1      1   true_pos\n",
       "16    1.626039 -0.248810     1      1   true_pos\n",
       "17    0.950911  0.108597     1      0  false_pos\n",
       "18    1.768602 -0.282775     1      1   true_pos\n",
       "19   -1.001561  0.075039     0      0   true_neg\n",
       "20   -0.644091  0.965015     0      0   true_neg\n",
       "21    0.269232 -0.548240     1      1   true_pos\n",
       "22    1.900681  0.467587     1      1   true_pos\n",
       "23   -0.872895  0.718372     0      0   true_neg\n",
       "24    0.453007  0.654407     0      0   true_neg\n",
       "25    0.645631  0.884851     0      0   true_neg\n",
       "26    2.208977  0.111426     1      1   true_pos\n",
       "27    1.119292 -0.559978     1      1   true_pos\n",
       "28   -0.862576  0.658330     0      0   true_neg\n",
       "29    0.146609 -0.363577     1      1   true_pos\n",
       "...        ...       ...   ...    ...        ...\n",
       "2469  0.641676 -0.851258     1      1   true_pos\n",
       "2470 -0.106102  0.662649     0      0   true_neg\n",
       "2471 -1.073335  0.236829     0      0   true_neg\n",
       "2472  0.053766  0.683436     0      0   true_neg\n",
       "2473  1.539834 -0.211039     1      1   true_pos\n",
       "2474  0.210459 -0.184545     1      1   true_pos\n",
       "2475  1.990283 -0.237843     1      1   true_pos\n",
       "2476  0.860376 -0.333342     1      1   true_pos\n",
       "2477  0.988905  0.348300     0      0   true_neg\n",
       "2478 -0.962078  0.742595     0      0   true_neg\n",
       "2479  0.473551  1.166360     0      0   true_neg\n",
       "2480  1.795304  0.124235     1      1   true_pos\n",
       "2481  0.448075  0.341434     0      0   true_neg\n",
       "2482  1.054459 -0.738213     1      1   true_pos\n",
       "2483  0.109742  0.888796     0      0   true_neg\n",
       "2484 -0.113794  0.993061     0      0   true_neg\n",
       "2485  0.727077 -0.490295     1      1   true_pos\n",
       "2486 -0.764201  0.827592     0      0   true_neg\n",
       "2487 -0.324356  1.259565     0      0   true_neg\n",
       "2488 -1.075145  0.284090     0      0   true_neg\n",
       "2489  1.706838 -0.303140     1      1   true_pos\n",
       "2490  0.691590 -0.511156     1      1   true_pos\n",
       "2491  0.156617  0.246852     1      1   true_pos\n",
       "2492  0.679288  0.798198     0      0   true_neg\n",
       "2493  0.070084  0.020167     1      1   true_pos\n",
       "2494  2.000023  0.565411     0      1  false_neg\n",
       "2495  0.423511 -0.404103     1      1   true_pos\n",
       "2496  0.163132  1.267795     0      0   true_neg\n",
       "2497  0.649928 -0.674249     1      1   true_pos\n",
       "2498  0.925592 -0.755120     1      1   true_pos\n",
       "\n",
       "[2499 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(testdata)\n",
    "df.columns=['X','Y']\n",
    "df['pred']=np.argmax(RES,1)\n",
    "df['label']=y[NObs*3/4+1:]\n",
    "\n",
    "def confusion (pred,label):\n",
    "    if    (pred==1) and (label==1): return ('true_pos')\n",
    "    elif  (pred==1) and (label==0): return ('false_pos')\n",
    "    elif  (pred==0) and (label==0): return ('true_neg')\n",
    "    else                          : return ('false_neg')\n",
    "\n",
    "def myfun(row):\n",
    "    return(confusion(row['pred'],row['label']))\n",
    "df['class']=df.apply(myfun,axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(df['X'],df['Y'],'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in grouped:\n",
    "    ax.plot(group.X, group.Y, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
